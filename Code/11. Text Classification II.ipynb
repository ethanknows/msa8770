{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_a = \"great for starters\"\n",
    "doc_b = \"great phone\"\n",
    "doc_c = \"fine quality\"\n",
    "doc_d = \"fine product\"\n",
    "doc_e = \"poor quality\"\n",
    "doc_f = \"poor phone\"\n",
    "\n",
    "\n",
    "train_doc = [doc_a,doc_b,doc_c,doc_d,doc_e,doc_f]\n",
    "train_target = [5,5,3,3,1,1]\n",
    "#Text preprocessing, tokenizing and filtering of stopwords are included in a high level \n",
    "#component that is able to build a dictionary of features and transform documents to feature vectors:\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_doc)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive bayes classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 1]\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['great for use', 'fine product','poor phone']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'awesome': True}, 'pos'), ({'outstanding': True}, 'pos'), ({'like': True}, 'pos'), ({'fantastic': True}, 'pos'), ({'terrific': True}, 'pos'), ({'good': True}, 'pos'), ({'nice': True}, 'pos'), ({'great': True}, 'pos')]\n",
      "[({'bad': True}, 'neg'), ({'terrible': True}, 'neg'), ({'useless': True}, 'neg'), ({'hate': True}, 'neg'), ({':(': True}, 'neg')]\n",
      "[({'movie': True}, 'neu'), ({'the': True}, 'neu'), ({'sound': True}, 'neu'), ({'was': True}, 'neu'), ({'is': True}, 'neu'), ({'actors': True}, 'neu'), ({'did': True}, 'neu'), ({'know': True}, 'neu'), ({'words': True}, 'neu'), ({'not': True}, 'neu')]\n",
      "[({'bad': True}, 'neg'), ({'terrible': True}, 'neg'), ({'useless': True}, 'neg'), ({'hate': True}, 'neg'), ({':(': True}, 'neg'), ({'awesome': True}, 'pos'), ({'outstanding': True}, 'pos'), ({'like': True}, 'pos'), ({'fantastic': True}, 'pos'), ({'terrific': True}, 'pos'), ({'good': True}, 'pos'), ({'nice': True}, 'pos'), ({'great': True}, 'pos'), ({'movie': True}, 'neu'), ({'the': True}, 'neu'), ({'sound': True}, 'neu'), ({'was': True}, 'neu'), ({'is': True}, 'neu'), ({'actors': True}, 'neu'), ({'did': True}, 'neu'), ({'know': True}, 'neu'), ({'words': True}, 'neu'), ({'not': True}, 'neu')]\n",
      "['awesome', 'movie,', 'i', 'like', 'it']\n",
      "awesome\n",
      "pos\n",
      "movie,\n",
      "neu\n",
      "i\n",
      "neu\n",
      "like\n",
      "pos\n",
      "it\n",
      "neu\n",
      "Subjectivity\n",
      "Neural: 0.6\n",
      "Polar: 0.4\n",
      "\n",
      "Polarity\n",
      "Positive: 1.0\n",
      "Negative: 0.0\n"
     ]
    }
   ],
   "source": [
    "#All of the NLTK classifiers work with featstructs, which can be simple dictionaries \n",
    "#mapping a feature name to a feature value. \n",
    "#For text, we’ll use a simplified bag of words model where every word is feature name \n",
    "#with a value of True. \n",
    "\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(words, True)])\n",
    " \n",
    "positive_vocab = ['awesome','outstanding', 'like', 'fantastic', 'terrific', 'good', 'nice', 'great']\n",
    "negative_vocab = ['bad', 'terrible','useless', 'hate', ':(']\n",
    "neutral_vocab = ['movie','the','sound','was','is','actors','did','know','words','not']\n",
    "\n",
    "\n",
    "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
    "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
    "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]\n",
    "\n",
    "print positive_features\n",
    "print negative_features\n",
    "print neutral_features\n",
    " \n",
    "train_set = negative_features + positive_features + neutral_features\n",
    "\n",
    "print train_set\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(train_set) \n",
    " \n",
    "# Predict\n",
    "neg = 0\n",
    "pos = 0\n",
    "neu = 0\n",
    "sentence = \"Awesome movie, I like it\"\n",
    "sentence = sentence.lower()\n",
    "words = sentence.split(' ')\n",
    "print words\n",
    "for word in words:\n",
    "    classResult = classifier.classify( word_feats(word))\n",
    "    print word\n",
    "    print classResult\n",
    "    if classResult == 'neg':\n",
    "        neg = neg + 1\n",
    "    if classResult == 'pos':\n",
    "        pos = pos + 1\n",
    "    if classResult == 'neu':\n",
    "        neu = neu + 1\n",
    "\n",
    "print \"Subjectivity\"\n",
    "print 'Neural: ' + str(float(neu)/len(words))\n",
    "print 'Polar: ' + str(1-float(neu)/len(words))\n",
    "\n",
    "print\n",
    "\n",
    "print \"Polarity\"\n",
    "print 'Positive: ' + str(float(pos)/(float(pos)+float(neg)))\n",
    "print 'Negative: ' + str(float(neg)/(float(pos)+float(neg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 1500 instances, test on 500 instances\n",
      "accuracy: 0.728\n",
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Use NLTK movie review data sets for sentiment analysis\n",
    "#Use 75% of the data set as the training data, and the rest 25% as the test data set.\n",
    "\n",
    "#NLTK comes with all the pieces you need to get started on sentiment analysis: \n",
    "#a movie reviews corpus with reviews categorized into pos and neg categories, \n",
    "#and a number of trainable classifiers. \n",
    "#We’ll start with a simple NaiveBayesClassifier as a baseline, using boolean word feature extraction.\n",
    "\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "#for f in negids:\n",
    "#    print ' '.join(movie_reviews.words(fileids=[f]))\n",
    " \n",
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    " \n",
    "negcutoff = len(negfeats)*3/4\n",
    "poscutoff = len(posfeats)*3/4\n",
    " \n",
    "trainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\n",
    "testfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n",
    "print 'train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats))\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
