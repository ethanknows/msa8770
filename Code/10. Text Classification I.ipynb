{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_a = \"great for starters\"\n",
    "doc_b = \"great for use anywhere\"\n",
    "doc_c = \"what a waste of money poor quality\"\n",
    "doc_d = \"the quality is poor waste of my time\"\n",
    "train_doc = [doc_a,doc_b,doc_c,doc_d]\n",
    "train_target = [0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great for starters', 'great for use anywhere', 'what a waste of money poor quality', 'the quality is poor waste of my time']\n",
      "[5, 5, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print train_doc\n",
    "print train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text preprocessing, tokenizing and filtering of stopwords are included in a high level \n",
    "#component that is able to build a dictionary of features and transform documents to feature vectors:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_doc)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 13)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 8)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 8)\t1\n",
      "  (3, 10)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 11)\t1\n"
     ]
    }
   ],
   "source": [
    "print X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t0.66767854461\n",
      "  (0, 1)\t0.52640543361\n",
      "  (0, 2)\t0.52640543361\n",
      "  (1, 0)\t0.555282664941\n",
      "  (1, 12)\t0.555282664941\n",
      "  (1, 1)\t0.437791231086\n",
      "  (1, 2)\t0.437791231086\n",
      "  (2, 8)\t0.372224851759\n",
      "  (2, 7)\t0.372224851759\n",
      "  (2, 4)\t0.472120026546\n",
      "  (2, 6)\t0.372224851759\n",
      "  (2, 13)\t0.372224851759\n",
      "  (2, 14)\t0.472120026546\n",
      "  (3, 11)\t0.392644137855\n",
      "  (3, 5)\t0.392644137855\n",
      "  (3, 3)\t0.392644137855\n",
      "  (3, 10)\t0.392644137855\n",
      "  (3, 8)\t0.309565148245\n",
      "  (3, 7)\t0.309565148245\n",
      "  (3, 6)\t0.309565148245\n",
      "  (3, 13)\t0.309565148245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "print X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_tfidf, train_target)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['great for use', 'poor quality']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t0.57735026919\n",
      "  (0, 1)\t0.57735026919\n",
      "  (0, 2)\t0.57735026919\n",
      "  (1, 5)\t0.707106781187\n",
      "  (1, 0)\t0.707106781187\n",
      "  (2, 4)\t0.707106781187\n",
      "  (2, 3)\t0.707106781187\n"
     ]
    }
   ],
   "source": [
    "doc_a = \"great for starters\"\n",
    "doc_b = \"fine quality\"\n",
    "doc_c = \"poor product\"\n",
    "train_doc = [doc_a,doc_b,doc_c]\n",
    "train_target = [5, 3, 1]\n",
    "#Text preprocessing, tokenizing and filtering of stopwords are included in a high level \n",
    "#component that is able to build a dictionary of features and transform documents to feature vectors:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train_doc)\n",
    "X_train_counts.shape\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "print X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVC and NuSVC implement the “one-against-one” approach (Knerr et al., 1990) \n",
    "#for multi- class classification. If n_class is the number of classes, then n_class * (n_class - 1) / 2\n",
    "#classifiers are constructed and each one trains data from two classes. \n",
    "#LinearSVC implements “one-vs-the-rest” multi-class strategy, \n",
    "#thus training n_class models. If there are only two classes, only one model is trained:\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(X_train_tfidf, train_target) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 1]\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['great for use', 'fine product','poor product']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = lin_clf.predict(X_new_tfidf)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
